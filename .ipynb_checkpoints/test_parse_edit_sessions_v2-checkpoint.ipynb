{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from changed_content_similarity import TextDiff, text_to_vector, get_cosine\n",
    "%run functions_wiki.py\n",
    "\n",
    "from itertools import combinations\n",
    "\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 'Apple is an American company.'\n",
    "B = 'Apple Inc is an American multinational technology company founded in 1978.'\n",
    "C = 'Apple Inc. is an American multinational technological company founded in 1976. It was found by Steve Jobs.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = TextDiff(A,B).getDiff(), TextDiff(B,C).getDiff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3380617018914066"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1, v2 = text_to_vector(a), text_to_vector(b)\n",
    "get_cosine(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TextDiff' object has no attribute 'getDiffIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-bc6e8cc2b02c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextDiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDiffIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextDiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetDiffIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextDiff' object has no attribute 'getDiffIndex'"
     ]
    }
   ],
   "source": [
    "a,b = TextDiff(A,B).getDiffIndex(), TextDiff(B,C).getDiffIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_distance(diff_index1, diff_index2):\n",
    "    center1, center2 = np.mean(diff_index1, axis=1), np.mean(diff_index2, axis=1)\n",
    "    distance1 = np.mean([np.min(np.abs(c-center2)) for c in center1])  # for each center in 1, search the nearest center in 2, calculate average distance \n",
    "    distance2 = np.mean([np.min(np.abs(c-center1)) for c in center2])\n",
    "    return min([distance1,distance2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_distance(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## calculate similarty of two random edits \n",
    "# import random\n",
    "\n",
    "# sample = random.sample(data.index.tolist(), 100)\n",
    "# from itertools import combinations\n",
    "# simi = []\n",
    "# for i, j in combinations(sample,2):\n",
    "#     a, b = TextDiff(data['text'][i-1],data['text'][i]).getDiff(), TextDiff(data['text'][j-1],data['text'][j]).getDiff()\n",
    "#     v1, v2 = text_to_vector(a), text_to_vector(b)\n",
    "#     simi.append(get_cosine(v1,v2))\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# %matplotlib inline \n",
    "\n",
    "# import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse top user edit session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../../data/NeXT_5.txt\", sep=\"\\t\")\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "data['text'] = data['text'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_sessionid(x, marker):\n",
    "    'x is user edit timestamp, return session id'\n",
    "    x = x.values\n",
    "    intervals = [61]\n",
    "    for i in range(1, len(x)):\n",
    "        intervals.append((x[i]-x[i-1]).astype('timedelta64[m]').astype(int))\n",
    "    intervals = np.where(np.array(intervals)>marker, 1, 0)\n",
    "    session_id, tmpid = [0], 0\n",
    "    for i in intervals[1:]:\n",
    "        if i > 0:\n",
    "            tmpid += 1\n",
    "        session_id.append(tmpid)\n",
    "    return np.array(session_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_user_session(file_path, N=3, marker = 60):\n",
    "    data = pd.read_csv(file_path, sep=\"\\t\")\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "    data = data.sort_values('timestamp').reset_index(drop=True)\n",
    "    data['text'] = data['text'].astype('str')\n",
    "#     N = int(np.round(len(set(data['user']))*percent))\n",
    "    sessions = []\n",
    "    top_users = data['user'].value_counts().index.tolist()[:N]\n",
    "    for user in top_users:\n",
    "        print(user)\n",
    "        mask_user = data['user'] == user\n",
    "        tmp = data[mask_user]  # user's edits in tmp dataframe\n",
    "        # mark session id\n",
    "        a = mark_sessionid(tmp['timestamp'], marker)\n",
    "        g = tmp.groupby(a)\n",
    "        for key, df in g:\n",
    "            default = {'username':user, 'session_id':key, 'start':min(df['timestamp']), \n",
    "                       'end':max(df['timestamp']), 'edit_num':len(df)}\n",
    "            index = df.index.tolist()\n",
    "            text1, text2 = data.ix[index[0]-1,'text'], data.ix[index[-1],'text']\n",
    "            diff = TextDiff(text1,text2)\n",
    "            default['changed_text'] = diff.getDiff()\n",
    "            default['changed_index'] = diff.getDiffIndex()\n",
    "            default['text_word_num'] = len(default['changed_text'].split(\" \"))\n",
    "            if default['edit_num'] > 1:\n",
    "                default['duration'] = (default['end'] - default['start']).total_seconds()/60  # chansfer into mins\n",
    "            else:\n",
    "                default['duration'] = np.nan\n",
    "            default['rev_id'] = \"|||\".join([str(c) for c in df['revid'].values])\n",
    "            sessions.append(default)\n",
    "    sessions = pd.DataFrame(sessions)\n",
    "    sessions['id'] = sessions['username'] + \"_\" + sessions['session_id'].astype('str')\n",
    "    sessions = sessions.sort_values('start').reset_index(drop=True)\n",
    "    return sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessing(text):\n",
    "#     text = re.sub(r'[^a-zA-Z0-9]', \" \", text)\n",
    "#     text = re.sub(r' +', \" \", text)\n",
    "#     return text\n",
    "# sessions['changed_text'] = sessions['changed_text'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEdge(x, kind):\n",
    "    if kind == \"index_similarity\":\n",
    "        if x < 50:  # mark 30 words as distance seperator. about 5% of the combinations.\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    if kind == \"content_similarity\":\n",
    "        if x > 0.4:  # content cosine similarity > 0.4\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    if kind == \"time_similarity\":\n",
    "        if x < 10800:   # time lag less than 3 hours\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edges(comb, sessions):\n",
    "    edges = {}\n",
    "    for item in comb:\n",
    "        default = {'index_similarity': 0, 'content_similarity': 0, 'time_similarity':0, 'edge_kind':\"000\", 'edge': 0}\n",
    "        \n",
    "        # index similarity\n",
    "        if item[1] - item[0] <= 3:\n",
    "            a,b = sessions.ix[item[0],\"changed_index\"],sessions.ix[item[1],\"changed_index\"]\n",
    "            if a and b:\n",
    "                default['index_similarity'] = isEdge(index_distance(a,b), 'index_similarity')\n",
    "        \n",
    "        # content similarity\n",
    "        a,b = sessions.ix[item[0],\"changed_text\"],sessions.ix[item[1],\"changed_text\"]\n",
    "        va,vb = text_to_vector(a), text_to_vector(b)\n",
    "        if a and b:\n",
    "            default['content_similarity'] = isEdge(get_cosine(va,vb), 'content_similarity')\n",
    "        \n",
    "        # time similarity\n",
    "        a,b = sessions.ix[item[0],\"start\"],sessions.ix[item[1],\"start\"]\n",
    "        if a and b:\n",
    "            default['time_similarity'] = isEdge((max([a,b]) - min([a,b])).total_seconds(), \"time_similarity\")\n",
    "        \n",
    "        default['edge_kind'] = str(default['index_similarity']) + str(default['content_similarity']) + str(default['time_similarity'])\n",
    "        if \"1\" in default['edge_kind']:\n",
    "            default['edge'] = 1\n",
    "        edges[item] = default\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(sessions, edges):\n",
    "    G = nx.Graph()\n",
    "    for i in sessions.index.tolist():\n",
    "        G.add_node(i)  # add all sessions\n",
    "    for i,j in edges.keys():\n",
    "#         if \"1\" in edges[(i,j)]['edge_kind'][1:]: # change to cosine similarity\n",
    "        if edges[(i,j)]['edge'] == 1:   # index similarity not work\n",
    "            G.add_edge(i,j,{'edge_kind':edges[(i,j)]['edge_kind']})\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_network_topology(G, nodes = []):\n",
    "    if len(nodes):\n",
    "        G = G.subgraph(nodes)\n",
    "    default = {\"isolate_nodes\": np.nan, \"connected_nodes\":np.nan, \"density\":np.nan, 'total_nodes':np.nan}\n",
    "    default['isolate_nodes'] = len(nx.isolates(G))\n",
    "    default['total_nodes'] = len(G.nodes())\n",
    "    default['connected_nodes'] = default['total_nodes'] - default['isolate_nodes']\n",
    "    default['density'] = nx.density(G)\n",
    "    return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['year'] = data['timestamp'].apply(lambda x: x.year)\n",
    "# sessions['year'] = sessions['start'].apply(lambda x: x.year)\n",
    "\n",
    "# g = data.groupby('year')\n",
    "# bursts = {}\n",
    "# for key, df in g:\n",
    "#     bursts[key] = cal_burstiness(get_time_intervals(df))\n",
    "\n",
    "# bursts = pd.DataFrame([bursts.keys(), bursts.values()], index=['year','burst']).T\n",
    "\n",
    "# g = sessions.groupby('year')\n",
    "# network_info = []\n",
    "# for key, df in g:\n",
    "#     nodes = np.arange(0, max(df.index))\n",
    "#     network_info.append(extract_network_topology(G, nodes=nodes))\n",
    "\n",
    "# tmp = pd.DataFrame(network_info)\n",
    "\n",
    "# tmp['year'] = set(sessions.year)\n",
    "\n",
    "# tmp2 = pd.merge(bursts, tmp, 'left')\n",
    "\n",
    "# tmp2\n",
    "\n",
    "# tmp2.ix[1:,['burst','connected_nodes','isolate_nodes']].plot(secondary_y='burst')\n",
    "# plt.show()\n",
    "\n",
    "# tmp2.ix[1:,['burst', 'density']].plot(secondary_y='burst')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot network dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = parse_user_session(\"../../data/NeXT_5.txt\", N = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_id = sessions.index.tolist()\n",
    "comb = combinations(node_id,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time edges = build_edges(comb, sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(edges).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['edge'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp['edge_kind'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges[(60,61)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(index_dis, bins=100)\n",
    "# plt.show()\n",
    "# np.percentile(index_dis, np.arange(0,100,5))  # mark 20 words as distance seperator. about 5% of the combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = build_network(sessions,edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(G.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_network_topology(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "mapping = dict(zip(set(sessions['username']), [plt.cm.Paired(c) for c in range(0,N)]))\n",
    "color = sessions['username'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.drawing.nx_agraph import graphviz_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  neato, dot, twopi, circo, fdp, nop, wc, acyclic, gvpr, gvcolor, ccomps, sccmap, tred, sfdp\n",
    "pos = graphviz_layout(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_color(G):\n",
    "    ecolor = []\n",
    "    for i,j in G.edges():\n",
    "        if G[i][j]['edge_kind'] == \"010\":  # content similar\n",
    "            ecolor.append('r')\n",
    "        elif G[i][j]['edge_kind'] == \"001\": # time similar\n",
    "            ecolor.append('b')\n",
    "        elif G[i][j]['edge_kind'] == '100':\n",
    "            ecolor.append('g')\n",
    "        else:\n",
    "            ecolor.append('y')\n",
    "    return ecolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "nx.draw_networkx(G, node_color=color, edge_color=edge_color(G), pos=pos, node_size=sessions['text_word_num'])\n",
    "# nx.draw_networkx(G, pos=pos, node_color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_time = (sessions['start'] > pd.to_datetime('20020101')) & (sessions['end'] < pd.to_datetime('20030101'))\n",
    "node = sessions[mask_time].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "G1 = nx.subgraph(G, node)\n",
    "nx.draw_networkx(G1, node_color=color[node], edge_color=edge_color(G1), pos=pos)\n",
    "# nx.draw_networkx(G, pos=pos, node_color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions.ix[node, ['duration','edit_num','text_word_num']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask = sessions['username'].apply(lambda x: x in set(['JoshuacUK','Tomhormby']))\n",
    "mask_time = (sessions['start'] > pd.to_datetime('20060101')) & (sessions['start'] < pd.to_datetime('20070101'))\n",
    "node = sessions[mask & mask_time].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "G1 = nx.subgraph(G, node)\n",
    "nx.draw_networkx(G1, node_color=color[node], edge_color=edge_color(G1), pos=pos)\n",
    "# nx.draw_networkx(G, pos=pos, node_color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_time = (sessions['start'] > pd.to_datetime('20070101')) & (sessions['end'] < pd.to_datetime('20080101'))\n",
    "node = sessions[mask_time].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "G1 = nx.subgraph(G, node)\n",
    "nx.draw_networkx(G1, node_color=color[node], edge_color=edge_color(G1), pos=pos)\n",
    "# nx.draw_networkx(G, pos=pos, node_color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_time = (sessions['start'] > pd.to_datetime('20080101')) & (sessions['end'] < pd.to_datetime('20090101'))\n",
    "node = sessions[mask_time].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "G1 = nx.subgraph(G, node)\n",
    "nx.draw_networkx(G1, node_color=color[node], edge_color=edge_color(G1), pos=pos)\n",
    "# nx.draw_networkx(G, pos=pos, node_color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster([108,104,139], sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster([144,145,147,141], sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cluster(node_list, sessions):\n",
    "    node_list = sorted(node_list)\n",
    "    for i in node_list:\n",
    "        print(i, sessions.ix[i,'username'])\n",
    "        print(sessions.ix[i,'rev_id'])\n",
    "        print(sessions.ix[i,'start'])\n",
    "        print(sessions.ix[i,'changed_text'])\n",
    "        print(\"===================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/w/index.php?title=NeXT&diff=prev&oldid=253609882\n",
    "# https://en.wikipedia.org/w/index.php?title=NeXT&diff=253609882&oldid=124057310"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster([34,94,96,95,97,106,154,155], sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster([33,165,164,133], sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster([7,85,26,28], sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster([64,65], sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster([48,53,64,88,89,90], sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster([137,138], sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_per_graph = len(G.nodes()) // 9\n",
    "fig = plt.figure(figsize=(25,25))\n",
    "cnt = 1\n",
    "for i in np.arange(nodes_per_graph,len(sessions),nodes_per_graph):\n",
    "    G1 = G.subgraph(np.arange(i))\n",
    "    fig.add_subplot(3,3,cnt)\n",
    "    nx.draw_networkx(G1, node_color=color.values[:i], with_labels=False, node_size=50, pos=pos, edge_color=edge_color(G1))\n",
    "    plt.title(\"first %s edit sessions\" %i + \"  ends in \"+str(sessions.ix[i,'end'].date()) ,size=15, weight='bold')\n",
    "    frame1 = plt.gca()\n",
    "    frame1.get_xaxis().set_visible(False)\n",
    "    frame1.get_yaxis().set_visible(False)\n",
    "    cnt += 1\n",
    "# fig.savefig('/Users/Nico/Desktop/collaboration_network.png',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(G.degree().values(),bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nx.connected_components(G):\n",
    "    if len(i)>1:\n",
    "        print(len(i))\n",
    "        print(set(sessions.ix[i,'username']))\n",
    "        print(min(sessions.ix[i,'start']))\n",
    "        print(max(sessions.ix[i,'end']))\n",
    "        print(\"======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster(np.arange(59,63), sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_cluster(np.arange(0,5), sessions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
